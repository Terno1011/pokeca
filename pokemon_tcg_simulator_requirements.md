# ポケモンカードゲームシミュレータ 要件定義書

## 1. プロジェクト概要

### 1.1 目的
ポケモンカードゲームの完全なデジタルシミュレータを開発し、AIエージェントによる強化学習を実装して、勝敗データの収集と戦略分析を行う。

### 1.2 目標
- 公式ルールに準拠したゲームシミュレータの実装
- AIエージェント同士の自動対戦システム
- 強化学習による戦略最適化
- 大量の対戦データ収集とパフォーマンス分析

## 2. システム要件

### 2.1 機能要件

#### 2.1.1 ゲームコア機能

**カードシステム**
- ポケモンカード（たね/1進化/2進化、HP、タイプ、ワザ、特性、弱点、抵抗力、逃げるコスト）
- エネルギーカード（基本エネルギー、特殊エネルギー）
- トレーナーズカード（グッズ、サポート、スタジアム）
- 特別ルールポケモン（ex、古代、未来、トレーナーのポケモン）

**フィールド管理**
- 山札（60枚デッキ、シャッフル機能）
- 手札（初期7枚、枚数制限なし）
- バトル場（バトルポケモン1匹）
- ベンチ（最大5匹）
- サイド（6枚、勝利条件）
- トラッシュ（使用済み・きぜつカード）

**ゲーム進行**
- 対戦準備（先攻/後攻決定、初期手札、たねポケモン確認、引き直しルール）
- ターン管理（先攻から開始、交互にターン実行）
- フェーズ管理（ドロー、メイン、アタック、ポケモンチェック）

#### 2.1.2 アクション処理

**基本アクション**
- カードドロー（ターン開始時必須、山札切れ負け判定）
- たねポケモン召喚（ベンチ上限5匹）
- エネルギー付与（1ターンに1枚まで）
- トレーナーズ使用（グッズ制限なし、サポート1ターン1枚）
- ポケモン進化（出した直後不可、連続進化不可）
- 特性発動（自動発動・任意発動の区別）
- ポケモン交代（逃げるコスト支払い、1ターン1回）
- ワザ使用（先攻１ターン目不可、必要エネルギー確認、ターン終了）

**ダメージ計算**
1. ワザの基本ダメージ
2. 攻撃側の効果適用
3. 弱点計算（2倍）
4. 抵抗力計算（指定値減算）
5. 防御側の効果適用
6. 最終ダメージ確定

#### 2.1.3 特殊状態管理

**状態種類**
- どく（ポケモンチェック時10ダメージ）
- やけど（ポケモンチェック時20ダメージ、コイン判定回復）
- ねむり（ワザ・逃げる禁止、コイン判定回復）
- マヒ（1ターンワザ・逃げる禁止、自動回復）
- こんらん（ワザ使用時コイン判定、失敗時30自己ダメージ）

**重複ルール**
- どく・やけど：他の特殊状態と重複可能
- ねむり・マヒ・こんらん：排他的（新しい状態で上書き）

#### 2.1.4 勝敗判定

**勝利条件**
1. サイド6枚獲得（相手ポケモンを倒して取得）
2. 相手の場にバトル可能ポケモンなし
3. 相手の山札切れ（ドロー時）

**きぜつ処理**
1. HP以上のダメージでポケモンきぜつ
2. 攻撃側がサイド1枚獲得（exポケモンは2枚）
3. きぜつポケモンと付属カードをトラッシュ
4. ベンチから新バトルポケモン選出

### 2.2 AIシステム要件

#### 2.2.1 強化学習エージェント

**学習アーキテクチャ**
- Deep Q-Network (DQN) または Policy Gradient方式
- 状態表現：ゲーム盤面の完全な状態ベクトル
- アクション空間：全ての有効なゲームアクション
- 報酬設計：勝利+1、敗北-1、中間報酬（ダメージ、サイド取得等）

**状態表現**
- 自分/相手の場のポケモン状態
- 手札情報（自分のみ）
- 山札残り枚数
- サイド残り枚数
- ターン数、フェーズ情報
- 特殊状態・効果情報

**アクション空間**
- ポケモン召喚（どのたねポケモンをどこに）
- エネルギー付与（どのエネルギーをどのポケモンに）
- トレーナーズ使用（どのカードをいつ）
- 進化（どのポケモンをどの進化カードで）
- 交代（どのポケモンと交代、逃げるコスト支払い）
- ワザ選択（どのワザを使用）
- ターン終了

#### 2.2.2 訓練システム

**自己対戦学習**
- 2つのAIエージェント同士の対戦
- エピソード単位での学習更新
- 勝率の追跡と評価
- 学習曲線の可視化

**カリキュラム学習**
- 簡単なデッキ構成から開始
- 段階的に複雑なカード・戦略を導入
- 多様な戦術の学習促進

### 2.3 データ収集・分析要件

#### 2.3.1 対戦データ

**記録項目**
- 全ターンの行動履歴
- ゲーム状態変遷
- 勝敗結果と要因
- 使用デッキ構成
- 対戦時間・ターン数

**統計分析**
- 勝率の推移
- 戦略の有効性評価
- カード使用頻度・効果
- ターン別行動パターン

#### 2.3.2 パフォーマンス指標

**学習進捗**
- エピソード別勝率
- 平均報酬の推移
- 探索率の変化
- 損失関数の収束

**戦略分析**
- デッキタイプ別勝率
- マッチアップ相性
- 序盤・中盤・終盤の戦術
- リスク管理能力

## 3. 技術仕様

### 3.1 システムアーキテクチャ

**コンポーネント構成**
```
├── Game Engine (ゲームルール実装)
│   ├── Card System (カード管理)
│   ├── Field Manager (フィールド状態)
│   ├── Action Processor (アクション処理)
│   └── Rule Validator (ルール検証)
├── AI Agent (学習エージェント)
│   ├── Neural Network (ニューラルネット)
│   ├── Training Loop (訓練ループ)
│   └── Strategy Evaluator (戦略評価)
├── Data Manager (データ管理)
│   ├── Game Logger (対戦記録)
│   ├── Statistics (統計処理)
│   └── Visualization (可視化)
└── Configuration (設定管理)
    ├── Card Database (カードDB)
    ├── Deck Templates (デッキテンプレート)
    └── Training Config (学習設定)
```

### 3.2 開発環境

**推奨技術スタック**
- 言語：Python 3.8+
- 機械学習：PyTorch / TensorFlow
- 強化学習：Stable-Baselines3 / Ray RLlib
- データ処理：Pandas / NumPy
- 可視化：Matplotlib / TensorBoard
- テスト：pytest

### 3.3 データベース設計

**カードマスタ**
- カード基本情報（名前、タイプ、レアリティ）
- ポケモン固有情報（HP、ワザ、特性）
- エネルギー・トレーナーズ情報

**対戦記録**
- 対戦ID、参加エージェント
- ターン別アクション
- 最終結果、統計情報

## 4. 実装フェーズ

### Phase 1: コアゲームエンジン
- 基本的なゲームルール実装
- カード・フィールド管理システム
- 簡易UI（デバッグ用）

### Phase 2: AI学習基盤
- 強化学習エージェント実装
- 状態表現・行動空間設計
- 基本的な自己対戦システム

### Phase 3: 高度な機能
- 複雑なカード効果実装
- 特殊状態・相互作用処理
- 学習効率向上

### Phase 4: データ分析・可視化
- 対戦データ収集システム
- 統計分析・レポート機能
- パフォーマンス可視化

## 5. 成功指標

### 5.1 技術的指標
- ゲームルールの正確な実装（100%のルール準拠）
- AIエージェントの学習成功（ランダム戦略に対して80%以上の勝率）
- システムの安定性（10,000対戦以上の連続実行）

### 5.2 学習効果指標
- 勝率の継続的改善
- 多様な戦略の発見
- 効率的なリソース管理の習得

### 5.3 データ収集指標
- 大規模対戦データの蓄積（10万対戦以上）
- 戦略パターンの分析結果
- カードバランスの定量的評価

## 6. リスクと対策

### 6.1 技術的リスク
- **複雑なルール実装**：段階的実装、テスト駆動開発
- **学習の収束性**：ハイパーパラメータ調整、報酬設計見直し
- **計算資源**：クラウド利用、分散学習の検討

### 6.2 設計リスク
- **状態空間の爆発**：抽象化レベルの調整
- **アクション空間の複雑性**：階層的行動選択の導入
- **評価の困難性**：多様な指標設定、人間プレイヤーとの比較

この要件定義書に基づいて、ポケモンカードゲームの公式ルールを完全に再現し、効果的な強化学習システムを構築することができます。